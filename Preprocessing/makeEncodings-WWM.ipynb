{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62030896-2adb-4358-90d2-f8868b541d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "#standard imports\n",
    "import torch\n",
    "import os\n",
    "from typing import List\n",
    "import time\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "\n",
    "#tokenizers and datasets\n",
    "import tokenizers\n",
    "from tokenizers import BertWordPieceTokenizer \n",
    "from tokenizers.processors import TemplateProcessing\n",
    "from transformers import BertTokenizer\n",
    "from whole_word_masking_ids import create_masked_lm_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3af5d0f-2b5e-43ab-999b-fbd962d0581c",
   "metadata": {},
   "source": [
    "#### Set data paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eca09c24-e880-4af1-8a00-5e95624fee5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['combined4Gb_1.txt', 'combined4Gb_2.txt']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vm_tok_path = '/home/americanthinker/notebooks/pytorch/NationalSecurityBERT/Preprocessing/Tokenization/wp-vocab-30500-vocab.txt'\n",
    "vm_data = '/home/americanthinker/notebooks/pytorch/NationalSecurityBERT/Data/text/partials/xaatest'\n",
    "checkpoint_path = '/home/americanthinker/notebooks/pytorch/NationalSecurityBERT/Modeling/checkpoints/'\n",
    "files = [f for f in os.listdir(vm_data) if os.path.isfile(os.path.join(vm_data, f)) and f.startswith('combined')]\n",
    "files = sorted(files)[:2]\n",
    "files\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391c7f68-7413-47b4-be37-b4bf0cfbf0f2",
   "metadata": {},
   "source": [
    "#### Load data from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c55f7d5d-afa2-413d-97ba-8d6eeb507a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_seq_512(path: str, sample_size:int=None) -> List[str]:\n",
    "    with open(path) as f:\n",
    "        if sample_size:\n",
    "            lines = [line.strip() for line in f.readlines()[:sample_size]]\n",
    "        else:\n",
    "            lines = [line.strip() for line in f.readlines()]\n",
    "    \n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "5c6f2148-2a9f-4c2b-9f55-66855d60f661",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_data_seq_512(os.path.join(vm_data, 'english_docs_aa.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "75e41d00-5381-496b-a553-fe11bb968269",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98862"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b84e09-aa59-4af7-865d-1d5fb78c31f6",
   "metadata": {},
   "source": [
    "#### Load tokenizer from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ecf5184-9eb6-43f9-a27a-f9aacded92da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tokenizer_from_file(vocab_path: str) -> BertWordPieceTokenizer:\n",
    "    tokenizer = BertWordPieceTokenizer(vocab_path, strip_accents=True, lowercase=True)\n",
    "    tokenizer.enable_truncation(max_length=512)\n",
    "    tokenizer.enable_padding()\n",
    "    tokenizer.post_processor = TemplateProcessing(\n",
    "        single=\"[CLS] $A [SEP]\",\n",
    "        pair=\"[CLS] $A [SEP] $B:1 [SEP]:1\",\n",
    "        special_tokens=[\n",
    "            (\"[CLS]\", tokenizer.token_to_id(\"[CLS]\")),\n",
    "            (\"[SEP]\", tokenizer.token_to_id(\"[SEP]\")),\n",
    "            (\"[MASK]\", tokenizer.token_to_id(\"[MASK]\"))\n",
    "        ],\n",
    "    )\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "004a35b9-6a08-4292-bcbc-ce38c6625f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = load_tokenizer_from_file('/home/americanthinker/notebooks/pytorch/NationalSecurityBERT/Preprocessing/Tokenization/wp-vocab-30500-vocab.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d83a5f31-e38a-411b-99a1-c032f5ad6cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_source_ids(tokenizer):\n",
    "    id_list = [tokenizer.token_to_id(word) for word in tokenizer.get_vocab()]\n",
    "    return id_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "531466d8-7662-41dd-8212-06f329f33376",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_list = create_source_ids(tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a556b1-56ad-434f-a73c-389a8d481ae7",
   "metadata": {},
   "source": [
    "#### Batch encode raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "a3b79067-bdf4-433c-91bf-4981ef2f87f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75.01 seconds\n"
     ]
    }
   ],
   "source": [
    "s = time.perf_counter()\n",
    "batch = tokenizer.encode_batch(data)\n",
    "e = time.perf_counter() - s\n",
    "print(round(e,2), 'seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8cfb22-9dc1-4e99-ba27-ded5ecbd3f8e",
   "metadata": {},
   "source": [
    "#### Prep dataset with Masked tokens @ 15%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "82a3fbea-b189-42e7-8bd7-8ea71532583f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlm_pipe(batch: List[tokenizers.Encoding], source_ids: list, tokenizer, mlm_prob=0.15) -> dict:\n",
    "    '''\n",
    "    Given a single instance from a batch of encodings, return masked inputs and associated arrays.\n",
    "    Converts tokenizer.Encoding into a pytorch tensor.\n",
    "    '''\n",
    "    \n",
    "    labels = torch.tensor([x.ids for x in tqdm(batch, 'Labels')])\n",
    "    mask = torch.tensor([x.attention_mask for x in tqdm(batch, 'Attention Mask')])\n",
    "    input_ids = torch.tensor([create_masked_lm_ids(x.ids, source_ids, tokenizer) for x in tqdm(batch, 'Input Ids')])\n",
    "    \n",
    "    #default masking prob = 15%, don't mask special tokens \n",
    "    \n",
    "    # rand = torch.rand(input_ids.shape)\n",
    "    # mask_arr = (rand < mlm_prob) * (input_ids > 4)\n",
    "    # for i in tqdm(range(input_ids.shape[0]), 'Masking Words'):\n",
    "    #     selection = torch.flatten(mask_arr[i].nonzero()).tolist()\n",
    "    #     input_ids[i, selection] = 4\n",
    "        \n",
    "   \n",
    "    encodings = {'input_ids': input_ids, 'attention_mask': mask, 'labels': labels}\n",
    "    return encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "f5e1e83a-40af-4390-a954-b7c94fb210d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14e9f183a3ea4c6c8edd4dc592fa52b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Labels:   0%|          | 0/98862 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c472ed5657247c2b89bfddc19da29a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Attention Mask:   0%|          | 0/98862 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "046f8316b1264e228e8ce60e4be69397",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Input Ids:   0%|          | 0/98862 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "encodings = mlm_pipe(batch, id_list, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "c797e86f-d8dc-4b1b-96b1-cb0bae64c9ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1203)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(sum(encodings['input_ids'] == 4)) / sum(sum(encodings['labels'] != 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "167bcd16-f984-460d-9f75-ba0deab5e584",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([98862, 512])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encodings['input_ids'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc051eef-e075-4ff3-a17e-eac96362c81e",
   "metadata": {},
   "source": [
    "#### Serialize encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fecc683b-fd48-49ff-9b61-d8bf11559076",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(encodings, './encodings.pt') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0091ba9a-df1a-490d-a1d8-6f02adccceee",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = torch.load('/home/americanthinker/notebooks/pytorch/NationalSecurityBERT/Data/encodings/encodings_395390_combined4Gb_1.txt.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "504f06b2-1704-459e-958f-21730e347fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_checker(num):\n",
    "    return list(zip([tokenizer.id_to_token(x) for x in encodings['input_ids'][num].detach().cpu().numpy()], [tokenizer.id_to_token(x) for x in encodings['labels'][num].detach().cpu().numpy()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "9f199cc0-32e0-4808-b8b5-d2a779168140",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('[CLS]', '[CLS]'),\n",
       " ('introduction', 'introduction'),\n",
       " ('under', 'under'),\n",
       " ('normal', 'normal'),\n",
       " ('physiological', 'physiological'),\n",
       " ('conditions', 'conditions'),\n",
       " (',', ','),\n",
       " ('all', 'all'),\n",
       " ('cells', 'cells'),\n",
       " ('in', 'in'),\n",
       " ('the', 'the'),\n",
       " ('[MASK]', 'body'),\n",
       " ('are', 'are'),\n",
       " ('exposed', 'exposed'),\n",
       " ('chronically', 'chronically'),\n",
       " ('to', 'to'),\n",
       " ('oxidants', 'oxidants'),\n",
       " ('from', 'from'),\n",
       " ('both', 'both'),\n",
       " ('endogenous', 'endogenous'),\n",
       " ('and', 'and'),\n",
       " ('exogenous', 'exogenous'),\n",
       " ('sources', 'sources'),\n",
       " ('[MASK]', ';'),\n",
       " ('yet', 'yet'),\n",
       " ('the', 'the'),\n",
       " ('[MASK]', 'intracellular'),\n",
       " ('“', '“'),\n",
       " ('redox', 'redox'),\n",
       " ('buffer', 'buffer'),\n",
       " ('”', '”'),\n",
       " ('mechanism', 'mechanism'),\n",
       " ('provides', 'provides'),\n",
       " ('significant', 'significant'),\n",
       " ('protection', 'protection'),\n",
       " ('[MASK]', 'mainly'),\n",
       " ('by', 'by'),\n",
       " ('the', 'the'),\n",
       " ('antioxidant', 'antioxidant'),\n",
       " ('network', 'network'),\n",
       " ('[', '['),\n",
       " ('1', '1'),\n",
       " (']', ']'),\n",
       " ('.', '.'),\n",
       " ('disturbance', 'disturbance'),\n",
       " ('in', 'in'),\n",
       " ('the', 'the'),\n",
       " ('[MASK]', 'pro'),\n",
       " ('[MASK]', '##oxid'),\n",
       " ('[MASK]', '##ant'),\n",
       " ('-', '-'),\n",
       " ('antioxidant', 'antioxidant'),\n",
       " ('balance', 'balance'),\n",
       " ('in', 'in'),\n",
       " ('favor', 'favor'),\n",
       " ('of', 'of'),\n",
       " ('the', 'the'),\n",
       " ('former', 'former'),\n",
       " ('[MASK]', 'leads'),\n",
       " ('to', 'to'),\n",
       " ('what', 'what'),\n",
       " ('is', 'is'),\n",
       " ('known', 'known'),\n",
       " ('as', 'as'),\n",
       " ('oxidative', 'oxidative'),\n",
       " ('stress', 'stress'),\n",
       " ('[', '['),\n",
       " ('2', '2'),\n",
       " (']', ']'),\n",
       " ('.', '.'),\n",
       " ('this', 'this'),\n",
       " ('oxidative', 'oxidative'),\n",
       " ('stress', 'stress'),\n",
       " ('and', 'and'),\n",
       " ('reactive', 'reactive'),\n",
       " ('oxygen', 'oxygen'),\n",
       " ('species', 'species'),\n",
       " ('(', '('),\n",
       " ('[MASK]', 'ros'),\n",
       " (')', ')'),\n",
       " ('can', 'can'),\n",
       " ('cause', 'cause'),\n",
       " ('damage', 'damage'),\n",
       " ('to', 'to'),\n",
       " ('dna', 'dna'),\n",
       " (',', ','),\n",
       " ('proteins', 'proteins'),\n",
       " ('and', 'and'),\n",
       " ('lipids', 'lipids'),\n",
       " ('an', 'an'),\n",
       " ('d', 'd'),\n",
       " ('end', 'end'),\n",
       " ('up', 'up'),\n",
       " ('with', 'with'),\n",
       " ('an', 'an'),\n",
       " ('epidemic', 'epidemic'),\n",
       " ('of', 'of'),\n",
       " ('non', 'non'),\n",
       " ('communicable', 'communicable'),\n",
       " ('chronic', 'chronic'),\n",
       " ('human', 'human'),\n",
       " ('diseases', 'diseases'),\n",
       " ('[', '['),\n",
       " ('3', '3'),\n",
       " ('[MASK]', '–'),\n",
       " ('[MASK]', '5'),\n",
       " (']', ']'),\n",
       " ('.', '.'),\n",
       " ('[MASK]', 'the'),\n",
       " ('prevalence', 'prevalence'),\n",
       " ('of', 'of'),\n",
       " ('ncd', 'ncd'),\n",
       " ('are', 'are'),\n",
       " ('at', 'at'),\n",
       " ('[MASK]', 'escal'),\n",
       " ('[MASK]', '##ating'),\n",
       " ('in', 'in'),\n",
       " ('egypt', 'egypt'),\n",
       " ('due', 'due'),\n",
       " ('to', 'to'),\n",
       " ('activation', 'activation'),\n",
       " ('[MASK]', 'of'),\n",
       " ('[MASK]', '64'),\n",
       " ('genes', 'genes'),\n",
       " ('involved', 'involved'),\n",
       " ('in', 'in'),\n",
       " ('inflammation', 'inflammation'),\n",
       " ('[', '['),\n",
       " ('6', '6'),\n",
       " (',', ','),\n",
       " ('7', '7'),\n",
       " (']', ']'),\n",
       " ('and', 'and'),\n",
       " ('other', 'other'),\n",
       " ('modifiable', 'modifiable'),\n",
       " ('risk', 'risk'),\n",
       " ('factors', 'factors'),\n",
       " ('[', '['),\n",
       " ('8', '8'),\n",
       " (']', ']'),\n",
       " ('.', '.'),\n",
       " ('medical', 'medical'),\n",
       " ('and', 'and'),\n",
       " ('pharmacologic', 'pharmacologic'),\n",
       " ('chemotherapeutic', 'chemotherapeutic'),\n",
       " ('agents', 'agents'),\n",
       " ('were', 'were'),\n",
       " ('reported', 'reported'),\n",
       " ('to', 'to'),\n",
       " ('reduce', 'reduce'),\n",
       " ('cardio', 'cardio'),\n",
       " ('vascular', 'vascular'),\n",
       " ('mortality', 'mortality'),\n",
       " ('among', 'among'),\n",
       " ('individuals', 'individuals'),\n",
       " ('at', 'at'),\n",
       " ('[MASK]', 'risk'),\n",
       " (',', ','),\n",
       " ('[MASK]', 'but'),\n",
       " ('they', 'they'),\n",
       " ('may', 'may'),\n",
       " ('[MASK]', 'induce'),\n",
       " ('[MASK]', 'oxidative'),\n",
       " ('stress', 'stress'),\n",
       " (',', ','),\n",
       " ('which', 'which'),\n",
       " ('increases', 'increases'),\n",
       " ('to', 'to'),\n",
       " ('an', 'an'),\n",
       " ('invasive', 'invasive'),\n",
       " ('stage', 'stage'),\n",
       " ('with', 'with'),\n",
       " ('[MASK]', 'disease'),\n",
       " ('progression', 'progression'),\n",
       " ('[', '['),\n",
       " ('9', '9'),\n",
       " (']', ']'),\n",
       " ('[MASK]', '.'),\n",
       " ('plant', 'plant'),\n",
       " ('polyphenols', 'polyphenols'),\n",
       " ('possess', 'possess'),\n",
       " ('the', 'the'),\n",
       " ('ideal', 'ideal'),\n",
       " ('chemical', 'chemical'),\n",
       " ('structure', 'structure'),\n",
       " ('[MASK]', 'for'),\n",
       " ('free', 'free'),\n",
       " ('radical', 'radical'),\n",
       " ('scavenging', 'scavenging'),\n",
       " ('activity', 'activity'),\n",
       " ('[MASK]', 'and'),\n",
       " ('their', 'their'),\n",
       " ('in', 'in'),\n",
       " ('germ', 'vitro'),\n",
       " ('antioxidative', 'antioxidative'),\n",
       " ('activities', 'activities'),\n",
       " ('are', 'are'),\n",
       " ('more', 'more'),\n",
       " ('effective', 'effective'),\n",
       " ('[MASK]', 'than'),\n",
       " ('[MASK]', 'tocopherol'),\n",
       " ('tall', '##s'),\n",
       " ('and', 'and'),\n",
       " ('ascorbate', 'ascorbate'),\n",
       " ('[MASK]', '['),\n",
       " ('10', '10'),\n",
       " (']', ']'),\n",
       " ('.', '.'),\n",
       " ('[MASK]', 'designing'),\n",
       " ('effective', 'effective'),\n",
       " ('preventive', 'preventive'),\n",
       " ('strategies', 'strategies'),\n",
       " ('using', 'using'),\n",
       " ('naturally', 'naturally'),\n",
       " ('occurring', 'occurring'),\n",
       " ('phyto', 'phyto'),\n",
       " ('##nutr', '##nutr'),\n",
       " ('##ients', '##ients'),\n",
       " ('aiming', 'aiming'),\n",
       " ('at', 'at'),\n",
       " ('reducing', 'reducing'),\n",
       " ('[MASK]', 'oxidative'),\n",
       " ('stress', 'stress'),\n",
       " ('[MASK]', 'is'),\n",
       " ('one', 'one'),\n",
       " ('of', 'of'),\n",
       " ('the', 'the'),\n",
       " ('cost', 'cost'),\n",
       " ('-', '-'),\n",
       " ('effective', 'effective'),\n",
       " ('strategies', 'strategies'),\n",
       " ('to', 'to'),\n",
       " ('move', 'move'),\n",
       " ('people', 'people'),\n",
       " ('’', '’'),\n",
       " ('s', 's'),\n",
       " ('[MASK]', 'lifestyle'),\n",
       " ('toward', 'toward'),\n",
       " ('healthier', 'healthier'),\n",
       " ('behaviors', 'behaviors'),\n",
       " ('[', '['),\n",
       " ('11', '11'),\n",
       " (']', ']'),\n",
       " ('.', '.'),\n",
       " ('pom', 'pom'),\n",
       " ('##eg', '##eg'),\n",
       " ('##ran', '##ran'),\n",
       " ('##ate', '##ate'),\n",
       " ('is', 'is'),\n",
       " ('a', 'a'),\n",
       " ('popular', 'popular'),\n",
       " ('fruit', 'fruit'),\n",
       " ('[MASK]', 'grown'),\n",
       " ('in', 'in'),\n",
       " ('egypt', 'egypt'),\n",
       " ('with', 'with'),\n",
       " ('annual', 'annual'),\n",
       " ('production', 'production'),\n",
       " ('of', 'of'),\n",
       " ('approximately', 'approximately'),\n",
       " ('1300', '1300'),\n",
       " ('##00', '##00'),\n",
       " ('tons', 'tons'),\n",
       " ('[MASK]', '['),\n",
       " ('12', '12'),\n",
       " (']', ']'),\n",
       " ('.', '.'),\n",
       " ('natural', 'natural'),\n",
       " ('unp', 'unp'),\n",
       " ('##rocess', '##rocess'),\n",
       " ('##ed', '##ed'),\n",
       " ('pom', 'pom'),\n",
       " ('##eg', '##eg'),\n",
       " ('##ran', '##ran'),\n",
       " ('##ate', '##ate'),\n",
       " ('juice', 'juice'),\n",
       " ('(', '('),\n",
       " ('pg', 'pg'),\n",
       " ('##j', '##j'),\n",
       " (')', ')'),\n",
       " ('is', 'is'),\n",
       " ('superior', 'superior'),\n",
       " ('出', 'to'),\n",
       " ('commercial', 'commercial'),\n",
       " ('juice', 'juice'),\n",
       " ('##s', '##s'),\n",
       " ('in', 'in'),\n",
       " ('their', 'their'),\n",
       " ('[MASK]', 'polyphenol'),\n",
       " ('(', '('),\n",
       " ('pp', 'pp'),\n",
       " (')', ')'),\n",
       " ('contents', 'contents'),\n",
       " ('with', 'with'),\n",
       " ('mean', 'mean'),\n",
       " ('levels', 'levels'),\n",
       " ('of', 'of'),\n",
       " ('[MASK]', '421'),\n",
       " ('and', 'and'),\n",
       " ('[MASK]', '382'),\n",
       " ('mg', 'mg'),\n",
       " ('per', 'per'),\n",
       " ('100', '100'),\n",
       " ('ml', 'ml'),\n",
       " (',', ','),\n",
       " ('respectively', 'respectively'),\n",
       " ('.', '.'),\n",
       " ('another', 'another'),\n",
       " ('investigation', 'investigation'),\n",
       " ('reported', 'reported'),\n",
       " ('respective', 'respective'),\n",
       " ('(', '('),\n",
       " ('pp', 'pp'),\n",
       " (')', ')'),\n",
       " ('concentrations', 'concentrations'),\n",
       " ('[MASK]', 'of'),\n",
       " ('139', '139'),\n",
       " ('mg', 'mg'),\n",
       " ('gallic', 'gallic'),\n",
       " ('acid', 'acid'),\n",
       " ('equivalent', 'equivalent'),\n",
       " ('(', '('),\n",
       " ('ga', 'ga'),\n",
       " ('##e', '##e'),\n",
       " (')', ')'),\n",
       " ('per', 'per'),\n",
       " ('100', '100'),\n",
       " ('ml', 'ml'),\n",
       " ('juice', 'juice'),\n",
       " ('and', 'and'),\n",
       " ('may', 'may'),\n",
       " ('[MASK]', 'reach'),\n",
       " ('over', 'over'),\n",
       " ('[MASK]', '200'),\n",
       " ('mg', 'mg'),\n",
       " ('ga', 'ga'),\n",
       " ('##e', '##e'),\n",
       " ('/', '/'),\n",
       " ('[MASK]', '100'),\n",
       " ('ml', 'ml'),\n",
       " (',', ','),\n",
       " ('when', 'when'),\n",
       " ('the', 'the'),\n",
       " ('other', 'other'),\n",
       " ('phenolic', 'phenolic'),\n",
       " ('compounds', 'compounds'),\n",
       " (';', ';'),\n",
       " ('anth', 'anth'),\n",
       " ('##ocy', '##ocy'),\n",
       " ('##amin', '##amin'),\n",
       " (',', ','),\n",
       " ('[MASK]', 'ell'),\n",
       " ('[MASK]', '##agi'),\n",
       " ('[MASK]', '##tan'),\n",
       " ('[MASK]', '##ni'),\n",
       " ('[MASK]', '##ns'),\n",
       " (',', ','),\n",
       " ('[MASK]', 'and'),\n",
       " ('tann', 'tann'),\n",
       " ('##in', '##in'),\n",
       " ('pun', 'pun'),\n",
       " ('##ical', '##ical'),\n",
       " ('##agin', '##agin'),\n",
       " ('[MASK]', 'were'),\n",
       " ('included', 'included'),\n",
       " ('[', '['),\n",
       " ('13', '13'),\n",
       " (']', ']'),\n",
       " ('.', '.'),\n",
       " ('dietary', 'dietary'),\n",
       " ('pom', 'pom'),\n",
       " ('##eg', '##eg'),\n",
       " ('##ran', '##ran'),\n",
       " ('##ate', '##ate'),\n",
       " ('intake', 'intake'),\n",
       " ('in', 'in'),\n",
       " ('human', 'human'),\n",
       " ('trials', 'trials'),\n",
       " ('elevated', 'elevated'),\n",
       " ('urinary', 'urinary'),\n",
       " ('[MASK]', 'excretion'),\n",
       " ('of', 'of'),\n",
       " ('the', 'the'),\n",
       " ('[MASK]', 'above'),\n",
       " ('mentioned', 'mentioned'),\n",
       " ('phenolic', 'phenolic'),\n",
       " ('##otyping', 'metabolites'),\n",
       " ('[MASK]', ','),\n",
       " ('which', 'which'),\n",
       " ('are', 'are'),\n",
       " ('the', 'the'),\n",
       " ('bioactive', 'bioactive'),\n",
       " ('constituents', 'constituents'),\n",
       " ('responsible', 'responsible'),\n",
       " ('for', 'for'),\n",
       " ('more', 'more'),\n",
       " ('than', 'than'),\n",
       " ('>', '>'),\n",
       " ('50', '50'),\n",
       " ('%', '%'),\n",
       " ('of', 'of'),\n",
       " ('the', 'the'),\n",
       " ('antioxidative', 'antioxidative'),\n",
       " ('[MASK]', 'capacity'),\n",
       " ('activity', 'activity'),\n",
       " ('of', 'of'),\n",
       " ('the', 'the'),\n",
       " ('juice', 'juice'),\n",
       " ('[', '['),\n",
       " ('14', '14'),\n",
       " (',', ','),\n",
       " ('15', '15'),\n",
       " (']', ']'),\n",
       " ('and', 'and'),\n",
       " ('are', 'are'),\n",
       " ('the', 'the'),\n",
       " ('biomarkers', 'biomarkers'),\n",
       " ('linked', 'linked'),\n",
       " ('to', 'to'),\n",
       " ('health', 'health'),\n",
       " ('promotion', 'promotion'),\n",
       " ('[', '['),\n",
       " ('16', '16'),\n",
       " (']', ']'),\n",
       " ('.', '.'),\n",
       " ('measurement', 'measurement'),\n",
       " ('of', 'of'),\n",
       " ('gst', 'gst'),\n",
       " ('[MASK]', 'activity'),\n",
       " ('had', 'had'),\n",
       " ('been', 'been'),\n",
       " ('recommended', 'recommended'),\n",
       " ('for', 'for'),\n",
       " ('[MASK]', 'the'),\n",
       " ('evaluation', 'evaluation'),\n",
       " ('of', 'of'),\n",
       " ('protective', 'protective'),\n",
       " ('treatment', 'treatment'),\n",
       " ('in', 'in'),\n",
       " ('##uates', 'trials'),\n",
       " ('considering', 'considering'),\n",
       " ('antioxidant', 'antioxidant'),\n",
       " ('[MASK]', 'strategies'),\n",
       " ('urethra', '.'),\n",
       " ('the', 'the'),\n",
       " ('expression', 'expression'),\n",
       " ('of', 'of'),\n",
       " ('the', 'the'),\n",
       " ('phase', 'phase'),\n",
       " ('ii', 'ii'),\n",
       " ('hepatic', 'hepatic'),\n",
       " ('glutathione', 'glutathione'),\n",
       " ('s', 's'),\n",
       " ('-', '-'),\n",
       " ('transferase', 'transferase'),\n",
       " ('was', 'was'),\n",
       " ('activated', 'activated'),\n",
       " ('[MASK]', 'in'),\n",
       " ('the', 'the'),\n",
       " ('liver', 'liver'),\n",
       " ('cells', 'cells'),\n",
       " ('of', 'of'),\n",
       " ('animals', 'animals'),\n",
       " ('[MASK]', 'following'),\n",
       " ('feeding', 'feeding'),\n",
       " ('pom', 'pom'),\n",
       " ('##eg', '##eg'),\n",
       " ('##ran', '##ran'),\n",
       " ('##ate', '##ate'),\n",
       " ('anthocyanins', 'anthocyanins'),\n",
       " ('flavonoids', 'flavonoids'),\n",
       " ('.', '.'),\n",
       " ('the', 'the'),\n",
       " ('[MASK]', 'molecular'),\n",
       " ('mechanism', 'mechanism'),\n",
       " ('was', 'was'),\n",
       " ('related', 'related'),\n",
       " ('to', 'to'),\n",
       " ('activation', 'activation'),\n",
       " ('[MASK]', 'of'),\n",
       " ('antioxidant', 'antioxidant'),\n",
       " ('[MASK]', 'response'),\n",
       " ('element', 'element'),\n",
       " ('(', '('),\n",
       " ('[MASK]', 'are'),\n",
       " (')', ')'),\n",
       " ('chromat', 'upstream'),\n",
       " ('of', 'of'),\n",
       " ('genes', 'genes'),\n",
       " ('that', 'that'),\n",
       " ('[MASK]', 'regulate'),\n",
       " ('the', 'the'),\n",
       " ('[MASK]', 'expression'),\n",
       " ('of', 'of'),\n",
       " ('gst', 'gst'),\n",
       " ('[MASK]', '['),\n",
       " ('17', '17'),\n",
       " (']', ']'),\n",
       " ('.', '.'),\n",
       " ('specific', 'specific'),\n",
       " ('strains', 'strains'),\n",
       " ('of', 'of'),\n",
       " ('lactic', 'lactic'),\n",
       " ('acid', 'acid'),\n",
       " ('bacteria', 'bacteria'),\n",
       " ('(', '('),\n",
       " ('lab', 'lab'),\n",
       " (')', ')'),\n",
       " ('possess', 'possess'),\n",
       " ('also', 'also'),\n",
       " ('antioxidative', 'antioxidative'),\n",
       " ('[SEP]', '[SEP]')]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_checker(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c6a2991-1a5e-4b0e-adb2-13cef84e81af",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = os.path.join(vm_data, files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d6dda779-2c42-4c12-8ba8-594ff972eb77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/americanthinker/notebooks/pytorch/NationalSecurityBERT/Data/text/combined4Gb_1.txt'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c406b86e-6286-48db-a98b-b7ca3ae038e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'combined4Gb_1.pt'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = file.split('/')[-1].split('.')[0]\n",
    "filename + '.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0203490f-33ed-4083-bb9d-a88dbc5ddd8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38_pytorch",
   "language": "python",
   "name": "conda-env-py38_pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
