{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "839b9be1-2d87-41da-999b-340dd1ff462e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertConfig, BertForMaskedLM\n",
    "from transformers import pipeline\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "420bdb13-b4d5-4873-9376-fae5f190ca8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_path = '/home/americanthinker/notebooks/pytorch/NationalSecurityBERT/Preprocessing/Tokenization/wp-vocab-30500-vocab.txt'\n",
    "checkpoint_folder = '/home/americanthinker/notebooks/pytorch/NationalSecurityBERT/Modeling/checkpoints/deepspeed_model/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87334ac5-3273-4d50-8ff0-72fee661e118",
   "metadata": {},
   "outputs": [],
   "source": [
    "alternative_tokenizer = BertTokenizer.from_pretrained(tokenizer_path)\n",
    "mask = alternative_tokenizer.mask_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91b98c85-fb79-43e1-a040-624916ef141b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_results(text: str, masked_word: str='', other_model='bert-base-uncased'):\n",
    "    config = BertConfig(vocab_size=30500)\n",
    "    model = BertForMaskedLM(config)\n",
    "    #model = BertForMaskedLM.from_pretrained(other_model)\n",
    "    untrained_pipe = pipeline('fill-mask', model=model, tokenizer=BertTokenizer.from_pretrained('bert-base-uncased'))\n",
    "    utresult = untrained_pipe(text)\n",
    "    print()\n",
    "    print(f\"Original Text: ['MASK'] = {masked_word}\")\n",
    "    print(\"*\" * 150)\n",
    "    print(text)\n",
    "    print()\n",
    "    print(f\"{other_model} Results\")\n",
    "    print(\"*\" * 150)\n",
    "    for result in utresult:\n",
    "        print(result['sequence'], result['score'])\n",
    "        \n",
    "    lm = BertForMaskedLM.from_pretrained(checkpoint_folder)\n",
    "    trained_pipe = pipeline('fill-mask', model=lm, tokenizer=alternative_tokenizer)\n",
    "\n",
    "    tresult = trained_pipe(text)\n",
    "    \n",
    "    print()\n",
    "    print(\"Trained Model Results\")\n",
    "    print(\"*\" * 150)\n",
    "    for result in tresult:\n",
    "        print(result['sequence'], result['score'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "351a772d-7c02-4359-88a5-35e942b5078d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original Text: ['MASK'] = \n",
      "******************************************************************************************************************************************************\n",
      "A hop, [MASK] and a jump away.\n",
      "\n",
      "bert-base-uncased Results\n",
      "******************************************************************************************************************************************************\n",
      "a hop,dilly and a jump away. 0.0002794562024064362\n",
      "a hop, coaster and a jump away. 0.0002541295252740383\n",
      "a hop, rc and a jump away. 0.00023797388712409884\n",
      "a hop, adoptive and a jump away. 0.0002312371216248721\n",
      "a hop, commended and a jump away. 0.0002137018454959616\n",
      "\n",
      "Trained Model Results\n",
      "******************************************************************************************************************************************************\n",
      "a hop, insignificant and a jump away. 0.0002824025577865541\n",
      "a hop, unprec and a jump away. 0.0002568446798250079\n",
      "a hop, leaflet and a jump away. 0.00024872017093002796\n",
      "a hop, counterstained and a jump away. 0.00021794498024974018\n",
      "a hop,â”´ and a jump away. 0.00021094358817208558\n"
     ]
    }
   ],
   "source": [
    "show_results(f'A hop, {mask} and a jump away.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702dcdad-493b-4c5d-9747-6c6d498a3af3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38_pytorch",
   "language": "python",
   "name": "conda-env-py38_pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
