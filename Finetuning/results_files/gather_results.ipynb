{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9223b8a-5784-422f-a9c1-e5d0f88ea5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae219205-08f4-4e75-b552-4df6e2b26753",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gather all fine tuning logs\n",
    "file_paths = ['Document_Classification/logs/doc_class_stats.txt',\n",
    "             'NER/logs/NER_stats.txt',\n",
    "             'QA/logs/QA_stats.txt',\n",
    "             'QA_BioASQ/logs/QA_BIO_stats.txt',\n",
    "            ]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc7b49f3-8371-4957-9e29-d1e85171fc6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "\n",
    "for path in file_paths:\n",
    "    label = path.split('/')[0]\n",
    "    results[label] = []\n",
    "    with open(path) as f:\n",
    "        for line in f.readlines():\n",
    "            output = json.loads(line)\n",
    "            temp = {'model_name': output['model_name'], 'metric': output['metric'], 'score':output['mean_score']}\n",
    "            results[label].append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd88756b-3f17-46e4-abd4-09d8267e1235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 Document_Classification\n",
      "10 NER\n",
      "10 QA\n",
      "10 QA_BioASQ\n"
     ]
    }
   ],
   "source": [
    "for key in results:\n",
    "    print(len(results[key]), key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "dbb220f9-b706-480f-9cc5-f5bccb099092",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_class = results['Document_Classification'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a1e7de3-d10a-4946-bca8-e1343b597bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = []\n",
    "for key in results:\n",
    "    df = pd.DataFrame(results[key])\n",
    "    frames.append(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "329b19e8-0c4b-4c79-b0e2-b651b2a22e36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>metric</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>f1-score</td>\n",
       "      <td>0.7898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>model-trained-0-3531-4GB</td>\n",
       "      <td>f1-score</td>\n",
       "      <td>0.7858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>model-trained-18-67089-4GB</td>\n",
       "      <td>f1-score</td>\n",
       "      <td>0.8114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>model-trained-36-130647-4GB</td>\n",
       "      <td>f1-score</td>\n",
       "      <td>0.8124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>run_8GB_model-trained-0-7063</td>\n",
       "      <td>f1-score (micro)</td>\n",
       "      <td>0.8051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>run_8GB_model-trained-8-63567</td>\n",
       "      <td>f1-score (micro)</td>\n",
       "      <td>0.8250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>run_8GB_model-trained-22-162449</td>\n",
       "      <td>f1-score (micro)</td>\n",
       "      <td>0.8293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>model-trained-0-10596-12GB</td>\n",
       "      <td>f1-score</td>\n",
       "      <td>0.8111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>model-trained-3-42384-12GB</td>\n",
       "      <td>f1-score</td>\n",
       "      <td>0.8143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>model-trained-5-63576-12GB</td>\n",
       "      <td>f1-score</td>\n",
       "      <td>0.8246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>run_4GB-wwm_model-trained-0-3531</td>\n",
       "      <td>f1-score (micro)</td>\n",
       "      <td>0.7946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>run_4GB-wwm_model-trained-18-67089</td>\n",
       "      <td>f1-score (micro)</td>\n",
       "      <td>0.8273</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            model_name            metric   score\n",
       "0                    bert-base-uncased          f1-score  0.7898\n",
       "1             model-trained-0-3531-4GB          f1-score  0.7858\n",
       "2           model-trained-18-67089-4GB          f1-score  0.8114\n",
       "3          model-trained-36-130647-4GB          f1-score  0.8124\n",
       "4         run_8GB_model-trained-0-7063  f1-score (micro)  0.8051\n",
       "5        run_8GB_model-trained-8-63567  f1-score (micro)  0.8250\n",
       "6      run_8GB_model-trained-22-162449  f1-score (micro)  0.8293\n",
       "7           model-trained-0-10596-12GB          f1-score  0.8111\n",
       "8           model-trained-3-42384-12GB          f1-score  0.8143\n",
       "9           model-trained-5-63576-12GB          f1-score  0.8246\n",
       "10    run_4GB-wwm_model-trained-0-3531  f1-score (micro)  0.7946\n",
       "11  run_4GB-wwm_model-trained-18-67089  f1-score (micro)  0.8273"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "6571ede2-ed59-4022-a252-e104683ec24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames[0] = frames[0].loc[0:9,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "f3e9f070-ae33-4917-9e52-aa383cb509ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretraining_corpus_size = ['20GB', '4GB', '4GB', '4GB', '8GB', '8GB', '8GB', '12GB', '12GB', '12GB']\n",
    "pretraining_steps = [1000000, 3500, 67000, 130000, 7063, 63500, 162449, 10500, 42000, 63500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "4a918ae1-78a1-4f8e-832f-027f964b6fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dc = pd.concat((frames[0], pd.Series(pretraining_corpus_size)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "81bcba6a-7143-4070-869f-1193675f4fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dc.rename(columns={0:'corpus_size'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "bb4e6713-e7b3-46c9-b788-df5f51877076",
   "metadata": {},
   "outputs": [],
   "source": [
    "dc = pd.concat((dc, pd.Series(pretraining_steps)), axis=1)\n",
    "dc.rename(columns={0:'pretraining_steps'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "304ade44-c0ea-4fd1-8a5b-b46044201bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names_8GB = ['model-trained-0-7063-8GB', 'model-trained-8-63567-8GB',\n",
    "       'model-trained-22-162449-8GB']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "e50ffa61-8928-4e51-a20c-2523f7ee5238",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, x in enumerate(range(4,7)):\n",
    "    dc.loc[x,'model_name'] = model_names_8GB[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "cfae017e-4d65-4f6b-a112-56d97899d55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dc.to_csv('doc_class_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "40319c13-a2ac-40f5-8ebf-98f7f8c3b597",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>metric</th>\n",
       "      <th>score</th>\n",
       "      <th>corpus_size</th>\n",
       "      <th>pretraining_steps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>model-trained-22-162449-8GB</td>\n",
       "      <td>f1-score (micro)</td>\n",
       "      <td>0.8293</td>\n",
       "      <td>8GB</td>\n",
       "      <td>162449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>model-trained-8-63567-8GB</td>\n",
       "      <td>f1-score (micro)</td>\n",
       "      <td>0.8250</td>\n",
       "      <td>8GB</td>\n",
       "      <td>63500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>model-trained-5-63576-12GB</td>\n",
       "      <td>f1-score (micro)</td>\n",
       "      <td>0.8246</td>\n",
       "      <td>12GB</td>\n",
       "      <td>63500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>model-trained-3-42384-12GB</td>\n",
       "      <td>f1-score (micro)</td>\n",
       "      <td>0.8143</td>\n",
       "      <td>12GB</td>\n",
       "      <td>42000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>model-trained-36-130647-4GB</td>\n",
       "      <td>f1-score (micro)</td>\n",
       "      <td>0.8124</td>\n",
       "      <td>4GB</td>\n",
       "      <td>130000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>model-trained-18-67089-4GB</td>\n",
       "      <td>f1-score (micro)</td>\n",
       "      <td>0.8114</td>\n",
       "      <td>4GB</td>\n",
       "      <td>67000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>model-trained-0-10596-12GB</td>\n",
       "      <td>f1-score (micro)</td>\n",
       "      <td>0.8111</td>\n",
       "      <td>12GB</td>\n",
       "      <td>10500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>model-trained-0-7063-8GB</td>\n",
       "      <td>f1-score (micro)</td>\n",
       "      <td>0.8051</td>\n",
       "      <td>8GB</td>\n",
       "      <td>7063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>f1-score (micro)</td>\n",
       "      <td>0.7898</td>\n",
       "      <td>20GB</td>\n",
       "      <td>1000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>model-trained-0-3531-4GB</td>\n",
       "      <td>f1-score (micro)</td>\n",
       "      <td>0.7858</td>\n",
       "      <td>4GB</td>\n",
       "      <td>3500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    model_name            metric   score corpus_size  \\\n",
       "6  model-trained-22-162449-8GB  f1-score (micro)  0.8293         8GB   \n",
       "5    model-trained-8-63567-8GB  f1-score (micro)  0.8250         8GB   \n",
       "9   model-trained-5-63576-12GB  f1-score (micro)  0.8246        12GB   \n",
       "8   model-trained-3-42384-12GB  f1-score (micro)  0.8143        12GB   \n",
       "3  model-trained-36-130647-4GB  f1-score (micro)  0.8124         4GB   \n",
       "2   model-trained-18-67089-4GB  f1-score (micro)  0.8114         4GB   \n",
       "7   model-trained-0-10596-12GB  f1-score (micro)  0.8111        12GB   \n",
       "4     model-trained-0-7063-8GB  f1-score (micro)  0.8051         8GB   \n",
       "0            bert-base-uncased  f1-score (micro)  0.7898        20GB   \n",
       "1     model-trained-0-3531-4GB  f1-score (micro)  0.7858         4GB   \n",
       "\n",
       "   pretraining_steps  \n",
       "6             162449  \n",
       "5              63500  \n",
       "9              63500  \n",
       "8              42000  \n",
       "3             130000  \n",
       "2              67000  \n",
       "7              10500  \n",
       "4               7063  \n",
       "0            1000000  \n",
       "1               3500  "
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dc.sort_values('score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "15297594-350d-40a9-8b27-c447a29b0fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dc['metric'] = 'f1-score (micro)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41b9d95-d5bb-4634-a252-e6c2509a9b6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
